{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOS6mhgT++x1cpnHYcWxJUO"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"R2kJm2gQSul9","executionInfo":{"status":"ok","timestamp":1753794447138,"user_tz":420,"elapsed":14,"user":{"displayName":"Ghuncha Nigar CSE Batch 21","userId":"14768215861040087510"}}},"outputs":[],"source":["import numpy as np\n","\n","# Softmax function\n","def softmax(z):\n","    e_z = np.exp(z - np.max(z, axis=1, keepdims=True))\n","    return e_z / e_z.sum(axis=1, keepdims=True)\n","\n","# Cross-entropy loss\n","def cross_entropy(y_true, y_pred):\n","    m = y_true.shape[0]\n","    return -np.sum(y_true * np.log(y_pred + 1e-8)) / m\n","\n","# One-hot encode labels\n","def one_hot(y, num_classes):\n","    return np.eye(num_classes)[y]\n","\n","# Batch GD with early stopping\n","def softmax_regression(X_train, y_train, X_val, y_val, lr=0.1, epochs=500, patience=10):\n","    m, n = X_train.shape\n","    num_classes = np.unique(y_train).size\n","    W = np.zeros((n, num_classes))\n","    b = np.zeros((1, num_classes))\n","\n","    y_train_oh = one_hot(y_train, num_classes)\n","    y_val_oh = one_hot(y_val, num_classes)\n","\n","    best_val_loss = np.inf\n","    best_W, best_b = None, None\n","    wait = 0\n","\n","    for epoch in range(epochs):\n","        # Forward pass\n","        logits = np.dot(X_train, W) + b\n","        probs = softmax(logits)\n","        loss = cross_entropy(y_train_oh, probs)\n","\n","        # Backpropagation\n","        grad_W = np.dot(X_train.T, (probs - y_train_oh)) / m\n","        grad_b = np.sum(probs - y_train_oh, axis=0, keepdims=True) / m\n","\n","        # Update weights\n","        W -= lr * grad_W\n","        b -= lr * grad_b\n","\n","        # Validation\n","        val_logits = np.dot(X_val, W) + b\n","        val_probs = softmax(val_logits)\n","        val_loss = cross_entropy(y_val_oh, val_probs)\n","\n","        if val_loss < best_val_loss:\n","            best_val_loss = val_loss\n","            best_W, best_b = W.copy(), b.copy()\n","            wait = 0\n","        else:\n","            wait += 1\n","            if wait >= patience:\n","                print(f\"Early stopping at epoch {epoch}\")\n","                break\n","\n","    return best_W, best_b\n"]}]}